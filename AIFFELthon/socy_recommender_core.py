import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_neo4j import Neo4jVector
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from neo4j import GraphDatabase
import re 
import random 

# --- 1. ê¸°ë³¸ ì„¤ì • ë° ì´ˆê¸°í™” ---
load_dotenv() # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ

# Neo4j ì ‘ì† ì •ë³´ ë° Google API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
NEO4J_URI = os.getenv("NEO4J_URI", "neo4j://localhost:7687")
NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ì–¸ì–´ ëª¨ë¸ ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(model="models/gemini-2.0-flash", temperature=0.3, top_k=5)
embedding_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

# Neo4j ë“œë¼ì´ë²„ ë° ë²¡í„° ì¸ë±ìŠ¤ ì—°ê²°
driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
neo4j_vector = Neo4jVector.from_existing_index(
    embedding=embedding_model,
    url=NEO4J_URI,
    username=NEO4J_USER,
    password=NEO4J_PASSWORD,
    index_name="paper_abstract_embeddings",
    text_node_property="text_for_embedding",
)

# --- 2. Neo4j ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜ ---
def get_full_paper_and_author_details(tx, paper_id):
    query = """
    MATCH (p:Paper {paperId: $paperId})
    OPTIONAL MATCH (p)-[:PUBLISHED_IN]->(j:Journal)
    WITH p, j, [(p)-[:HAS_AUTHOR]->(a) | {
        name: a.name,
        hIndex: a.hIndex,
        citationCount: a.citationCount
    }] AS authors
    RETURN p as paper, authors, j.journalName AS journalName
    """
    result = tx.run(query, paperId=paper_id).single()
    if result:
        return {
            "paper": dict(result["paper"]),
            "authors": result["authors"],
            "journalName": result["journalName"]
        }
    return None

def get_ultimate_context(question: str) -> str:
    def is_latin(text):
        return all(ord(c) < 128 or c.isspace() for c in text)

    # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (ë§ì´ ë½‘ê³  ë‚˜ì¤‘ì— í•„í„°ë§)
    similar_nodes = neo4j_vector.similarity_search(question, k=20)
    filtered_nodes = [n for n in similar_nodes if 'language' not in n.metadata or n.metadata['language'] in ['en', 'ko']]

    if not filtered_nodes:
        return "ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    recommendations = {}
    with driver.session(database="neo4j") as session:
        for node in filtered_nodes[:5]:
            paper_id = node.metadata['paperId']
            recommendations[paper_id] = {'reasons': ['ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì£¼ì œë¥¼ ë‹¤ë£¸'], 'score': 1.0}

        most_relevant_paper_id = filtered_nodes[0].metadata['paperId']

        author_recs = session.run("""
            MATCH (seed:Paper {paperId: $paperId})-[:HAS_AUTHOR]->(author:Author)
            WHERE author.hIndex > 10 OR author.citationCount > 1000
            MATCH (rec:Paper)-[:HAS_AUTHOR]->(author)
            WHERE seed <> rec
            RETURN rec.paperId AS paperId, 'í•µì‹¬ ë…¼ë¬¸ì˜ ì˜í–¥ë ¥ ìˆëŠ” ì €ì(' + author.name + ')ê°€ ì €ìˆ ' AS reason, rec.citationCount AS score
            LIMIT 2
        """, paperId=most_relevant_paper_id)
        for rec in author_recs:
            if rec['paperId'] not in recommendations:
                recommendations[rec['paperId']] = {'reasons': [], 'score': 0}
            recommendations[rec['paperId']]['reasons'].append(rec['reason'])
            recommendations[rec['paperId']]['score'] += rec['score'] * 5

        cocitation_recs = session.run("""
            MATCH (seed:Paper {paperId: $paperId})<-[:CITES]-(citer:Paper)
            WITH seed, collect(citer) AS citers
            UNWIND citers AS citer
            MATCH (citer)-[:CITES]->(rec:Paper)
            WHERE seed <> rec AND NOT (rec)-[:CITES]->(seed) AND NOT (seed)-[:CITES]->(rec)
            RETURN rec.paperId AS paperId, 'í•¨ê»˜ ìì£¼ ì¸ìš©ë¨ (í•™ìˆ ì  ì—°ê´€ì„± ë†’ìŒ)' AS reason, count(citer) AS score
            ORDER BY score DESC
            LIMIT 2
        """, paperId=most_relevant_paper_id)
        for rec in cocitation_recs:
            if rec['paperId'] not in recommendations:
                recommendations[rec['paperId']] = {'reasons': [], 'score': 0}
            recommendations[rec['paperId']]['reasons'].append(rec['reason'])
            recommendations[rec['paperId']]['score'] += rec['score'] * 10

        sorted_recs = sorted(recommendations.items(), key=lambda item: item[1]['score'], reverse=True)
        top_recs_info = []
        for paper_id, data in sorted_recs[:5]:
            details = session.execute_read(get_full_paper_and_author_details, paper_id)
            if details and is_latin(details['paper'].get('title', '')):
                top_recs_info.append({'details': details, 'reasons': data['reasons']})

        def format_authors(authors_list):
            if not authors_list:
                return 'N/A'
            return ', '.join([
                f"{a.get('name', 'N/A')} (h-index: {a.get('hIndex', 0)}, ì´ ì¸ìš©: {a.get('citationCount', 0)})"
                for a in authors_list
            ])

        full_context = ""
        if top_recs_info:
            full_context += "### ì¶”ì²œ ë…¼ë¬¸ ëª©ë¡ ###\n"
            for i, rec in enumerate(top_recs_info):
                details = rec['details']['paper']
                authors_formatted = format_authors(rec['details']['authors'])
                journal_name = rec['details']['journalName']
                reasons = rec['reasons']
                full_context += f"""
[ì¶”ì²œ {i+1}] {details.get('title', 'N/A')} ({details.get('year', 'N/A')})
- ì €ì: {authors_formatted}
- ì €ë„: {journal_name if journal_name else 'N/A'}
- ì¸ìš© ìˆ˜: {details.get('citationCount', 0)}
- **ì¶”ì²œ í•µì‹¬ ê·¼ê±°:** {' / '.join(reasons)}
"""
        return full_context

# --- 3. ìµœì¢… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ---
template = """
ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ ì‚¬íšŒí•™ ì—°êµ¬ìì´ì, ê¹Šì€ í†µì°°ì„ ì§€ë‹Œ ì„í•™ì…ë‹ˆë‹¤.
í•™ìƒë“¤ê³¼ ì‹ ì§„ ì—°êµ¬ìë“¤ì„ ì§€ë„í•˜ë©°, ê·¸ë“¤ì˜ ì§ˆë¬¸ì— ë‹´ê¸´ ë¬¸ì œì˜ì‹ê³¼ ì´ë¡ ì  ë§¥ë½ì„ ë‚ ì¹´ë¡­ê²Œ íŒŒì•…í•´, ê°€ì¥ ì ì ˆí•œ ë…¼ë¬¸ë“¤ì„ ì•ˆë‚´í•´ì£¼ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.

ì´ì œ ë‹¹ì‹ ì—ê²ŒëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì¤‘ìš”í•œ ì„ë¬´ê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤.

<ë‹¹ì‹ ì˜ ì—­í• >
1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ê³  ì˜ë¯¸ ìˆëŠ” ë…¼ë¬¸ë“¤ì„ ì¶”ì²œ ëª©ë¡ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ë¨¼ì € ì „ì²´ ëª©ë¡ì— ëŒ€í•œ ê°„ë‹¨í•œ ê°œìš”ë¥¼ ì•Œë ¤ì¤€ ë’¤, í•˜ë‚˜ì”© ë…¼ë¬¸ì„ ì†Œê°œí•´ì£¼ì„¸ìš”.
2. ê° ë…¼ë¬¸ì„ ì†Œê°œí•  ë•ŒëŠ”, ë°˜ë“œì‹œ 'ì¶”ì²œ í•µì‹¬ ê·¼ê±°'ë¡œ ë¬¸ì¥ì„ ì‹œì‘í•œ ë’¤, ê·¸ ë…¼ë¬¸ì´ ì™œ ì¤‘ìš”í•œì§€, ì–´ë–¤ ë¬¸ì œì˜ì‹ì— ê¸°ë°˜í–ˆëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–¤ ì‚¬íšŒí•™ì  ì „í†µì´ë‚˜ ë…¼ì˜ì— ê¸°ì—¬í•˜ëŠ”ì§€ë¥¼ ì´ì•¼ê¸°í•˜ë“¯ ì„œìˆ í•˜ì„¸ìš”.
- ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹ˆë¼, ê·¸ ë…¼ë¬¸ì´ í•™ê³„ì—ì„œ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ë¥¼ í’ë¶€í•œ ë¬¸ë§¥ê³¼ í•¨ê»˜ ì†Œê°œí•´ì•¼ í•©ë‹ˆë‹¤.
- ë¬¸ì¥ì€ ë§ˆì¹¨í‘œ(.)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆí•˜ì„¸ìš”.
3. ì‹ ë¢°ì„±ê³¼ ê¹Šì´ë¥¼ ë”í•˜ê¸° ìœ„í•´, ë‹¤ìŒ ì •ë³´ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”:
- ì£¼ìš” ì €ìì˜ ì˜í–¥ë ¥ (ì˜ˆ: h-index, ì´ ì¸ìš© ìˆ˜ ë“±)
- ë…¼ë¬¸ì´ ê²Œì¬ëœ ì €ë„ì˜ ëª…ì„±
- í•´ë‹¹ ë…¼ë¬¸ì˜ ì¸ìš© ìˆ˜
ì˜ˆì‹œ:
â€œì´ ë…¼ë¬¸ì€ ê°ì •ì‚¬íšŒí•™ì˜ ê¶Œìœ„ìì¸ Arlie Hochschild(h-index: 70, ì´ ì¸ìš© ìˆ˜: 50,000íšŒ ì´ìƒ) êµìˆ˜ê°€ ì§‘í•„í–ˆìœ¼ë©°, ì‚¬íšŒí•™ê³„ì˜ ëª…ì €ë„ì¸ [ì €ë„ëª…]ì— ê²Œì¬ë˜ì—ˆìŠµë‹ˆë‹¤.â€

4. ë…¼ë¬¸ ê°„ì˜ ì—°ê´€ì„±ë„ ê°•ì¡°í•˜ì„¸ìš”.=
- ì´ë¡ ì  ì „í†µ, ê³µí†µëœ ë¬¸ì œì˜ì‹, ë°©ë²•ë¡ ì  ì ‘ê·¼ ë“±ì´ ì–´ë–»ê²Œ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ë©°, í•˜ë‚˜ì˜ ì´ì•¼ê¸° íë¦„ ì•ˆì—ì„œ ë…¼ë¬¸ë“¤ì´ ì„œë¡œ ì–´ë–»ê²Œ ë§¥ë½ì„ ì´ë£¨ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”.

<ì‘ì„± ë°©ì‹ ê·œì¹™>
1. ëª¨ë“  ì œëª© ë° ë¶€ì œëª©ì€ Markdownì˜ ##, ###ë¥¼ ì‚¬ìš©í•˜ê³ , ì•ë’¤ë¡œ ë¹ˆ ì¤„ì„ ë„£ì–´ êµ¬ë¶„í•˜ì„¸ìš”.
2. ëª©ë¡ í•­ëª©(1., -, *)ì€ ê° ì¤„ì„ ë¶„ë¦¬í•´ ëª…í™•í•˜ê²Œ í‘œì‹œí•˜ë˜, ë¶ˆí•„ìš”í•œ ë¹ˆ ì¤„ì€ ë„£ì§€ ë§ˆì„¸ìš”.
3. ëª¨ë“  ë¬¸ì¥ì€ ë§ˆì¹¨í‘œë¡œ ëë‚œ ë’¤ ì¤„ë°”ê¿ˆí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¨, ì•½ì–´ë‚˜ ìˆ«ì ë’¤ëŠ” ì˜ˆì™¸ì…ë‹ˆë‹¤.
4. ì‚¬ìš©ì ì§ˆë¬¸ì´ ë„ˆë¬´ ëª¨í˜¸í•˜ê±°ë‚˜ í•™ìˆ ì ì´ì§€ ì•Šìœ¼ë©´, ê´€ë ¨ ë…¼ë¬¸ì´ ì—†ë‹¤ê³  ì •ì¤‘íˆ ì•ˆë‚´í•˜ê³ , ë” êµ¬ì²´ì ì´ê³  í•™ë¬¸ì ì¸ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”.
5. í•„ìš”í•˜ë‹¤ë©´, ì§ˆë¬¸ì„ í•´ì„í•  ë•Œ ê°ì •ì‚¬íšŒí•™, ë¯¸ì‹œì‚¬íšŒí•™, êµ¬ì¡°ì£¼ì˜, êµ¬ì„±ì£¼ì˜ ë“± ë‹¤ì–‘í•œ ì‚¬íšŒí•™ì  ì‹œê°ì„ ê°„ë‹¨íˆ ì†Œê°œí•˜ë©° í•™ë¬¸ì  ê¹Šì´ë¥¼ ë”í•˜ì„¸ìš”.

<ë‹µë³€ ë°©ì‹ ê°€ì´ë“œ>
1. ê° ë…¼ë¬¸ ì†Œê°œëŠ” ë§ì„ ê±´ë„¤ë“¯, ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ íë¦„ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
- ë‹¨ìˆœíˆ â€œì´ ë…¼ë¬¸ì€â€¦â€ì´ ì•„ë‹ˆë¼, â€œì´ ì—°êµ¬ëŠ” ê°ì •ì´ ë‹¨ìˆœí•œ ì‹¬ë¦¬ í˜„ìƒì´ ì•„ë‹ˆë¼ ì‚¬íšŒì ìœ¼ë¡œ êµ¬ì„±ëœë‹¤ëŠ” ê´€ì ì„ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤â€ì²˜ëŸ¼ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. ë…¼ë¬¸ í•µì‹¬ ë‚´ìš©ì„ ì„¤ëª…í•  ë•ŒëŠ” ì˜ˆì‹œë‚˜ êµ¬ì²´ì  ê°œë…ì„ ì‚¬ìš©í•˜ì—¬ ë…ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì£¼ì„¸ìš”.
- ì˜ˆ: â€œScheffëŠ” ì‚¬íšŒì ìœ¼ë¡œ ì •ì˜í•˜ê¸° ì• ë§¤í•œ í–‰ë™ì´ ì–´ë–»ê²Œ â€˜ì •ì‹  ì§ˆí™˜â€™ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ë©°â€¦â€
3. ê°ê°ì˜ ë…¼ë¬¸ì´ ì–´ë–¤ í•™ë¬¸ì  ì „í†µ ë˜ëŠ” íë¦„ ì†ì— ìˆëŠ”ì§€, í˜¹ì€ ê¸°ì¡´ ì´ë¡ ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥´ê±°ë‚˜ ì—°ê²°ë˜ëŠ”ì§€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•˜ì„¸ìš”.
4. ë¬¸ì¥ ì‚¬ì´ì—ëŠ” ë¶€ë“œëŸ¬ìš´ ì—°ê²°ì–´ë¥¼ ë„£ì–´ ë§ì˜ íë¦„ì„ ìœ ë„í•˜ì„¸ìš”.
- â€œì´ì™€ ë‹¬ë¦¬â€, â€œë˜í•œâ€, â€œíŠ¹íˆ ì£¼ëª©í•  ì ì€â€¦â€, â€œì˜ˆë¥¼ ë“¤ì–´â€ ë“±
5. ë…¼ë¬¸ ì •ë³´(ì €ì, ì €ë„, ì¸ìš© ìˆ˜)ëŠ” ì„œì‚¬ ì†ì— ë…¹ì—¬ì„œ ì „ë‹¬í•˜ì„¸ìš”.
- (X) â€œì´ ì¸ìš© ìˆ˜: 5,000â€
- (O) â€œì´ ë…¼ë¬¸ì€ ì´ 5,000íšŒ ì´ìƒ ì¸ìš©ë˜ë©°, ê°ì •ì‚¬íšŒí•™ì—ì„œ ê³ ì „ìœ¼ë¡œ í‰ê°€ë°›ìŠµë‹ˆë‹¤.â€
6. ë§ˆì¹˜ ê°•ì—° ì¤‘ í•˜ë‚˜í•˜ë‚˜ ì„¤ëª…í•˜ëŠ” ê²ƒì²˜ëŸ¼ êµ¬ì„±í•˜ì„¸ìš”.
- ğŸ“Œ ì˜ˆì‹œ ìŠ¤íƒ€ì¼
ì´ ë…¼ë¬¸ì€ ê°ì •ì´ ì‚¬íšŒì ìœ¼ë¡œ êµ¬ì„±ëœë‹¤ëŠ” ê´€ì ì„ ë’·ë°›ì¹¨í•˜ëŠ” ëŒ€í‘œì  ì—°êµ¬ì…ë‹ˆë‹¤.
ì €ì Thomas ScheffëŠ” â€˜ì”ì—¬ ê·œì¹™ ìœ„ë°˜â€™ì´ë¼ëŠ” ê°œë…ì„ í†µí•´, ëª…í™•íˆ ê·œì •ë˜ì§€ ì•ŠëŠ” í–‰ë™ë“¤ì´ ì–´ë–»ê²Œ ì‚¬íšŒì  ë‚™ì¸ì„ í†µí•´ â€˜ì •ì‹  ì§ˆí™˜â€™ìœ¼ë¡œ ê·œì •ë˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
ì´ ë…¼ë¬¸ì€ ì •ì‹  ì§ˆí™˜ì„ ë‹¨ìˆœíˆ ê°œì¸ì˜ ë¬¸ì œë¡œ ë³´ì§€ ì•Šê³ , ì‚¬íšŒì  ìƒí˜¸ì‘ìš©ê³¼ ê·œë²”ì˜ ì‚°ë¬¼ë¡œ ì´í•´í•´ì•¼ í•œë‹¤ëŠ” ì „í™˜ì ì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤.
ì´í›„ ë‚™ì¸ ì´ë¡ ê³¼ ì •ì‹ ì§ˆí™˜ ì‚¬íšŒí•™ì˜ ì£¼ìš” ì´ë¡ ì  ê¸°ë°˜ì´ ë˜ì—ˆìœ¼ë©°, ScheffëŠ” ì´ ë¶„ì•¼ì—ì„œ ë§¤ìš° ì˜í–¥ë ¥ ìˆëŠ” í•™ìë¡œ í‰ê°€ë°›ìŠµë‹ˆë‹¤.
ì´ ì—°êµ¬ëŠ” Aldine Transactionì—ì„œ ì¶œíŒë˜ì—ˆê³ , í˜„ì¬ê¹Œì§€ 2,000íšŒ ì´ìƒ ì¸ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.


**Context:**
{context}

**User's Request:**
{question}

**Answer:**
"""

prompt = ChatPromptTemplate.from_template(template)

chain = (
    {"context": RunnableLambda(get_ultimate_context), "question": RunnableLambda(lambda x: x)}
    | prompt
    | llm
    | StrOutputParser()
)

# --- ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ---
if __name__ == "__main__":
    print("ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” ğŸ“SOCY AssistantğŸ“ì…ë‹ˆë‹¤.")
    print("ì‚¬íšŒí•™ ì—°êµ¬ ë¶„ì•¼ë¥¼ ê¹Šì´ ìˆê²Œ íƒìƒ‰í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
    print("ì €ëŠ” ì‚¬íšŒí•™ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ,")
    print("ì§ˆë¬¸í•˜ì‹  ì£¼ì œì™€ ê´€ë ¨ëœ í•µì‹¬ ë…¼ë¬¸ì„ ì°¾ì•„ë‚´ê³ ,")
    print("ê·¸ ì´í•´ë¥¼ ë„“í˜€ì¤„ ì—°ê´€ ì—°êµ¬ë“¤ì„ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.")
    print("ë§ˆì¹˜ ì§€ë„êµìˆ˜ë‹˜ê³¼ì˜ ì‹¬ë„ ê¹Šì€ í•™ë¬¸ì  ëŒ€í™”ë¥¼ ê²½í—˜í•˜ëŠ” ê²ƒì²˜ëŸ¼,")
    print("ì¶”ì²œ ë…¼ë¬¸ë“¤ì˜ ì—°ê²° ê³ ë¦¬ì™€ í•™ë¬¸ì  ì˜ì˜ë¥¼ ëª…í™•í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.")
    print("í•™ìˆ ì ì¸ ì§ˆë¬¸ì„ ë˜ì ¸ì£¼ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")
    
    while True:
        question = input(">> ") # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¨¼ì € ë°›ìŒ

        if question.lower() == 'exit':
            break
        
        # --- ì‚¬ìš©ì ì§ˆë¬¸ ì¶œë ¥ ì¶”ê°€ ---
        print(f"\n[ì‚¬ìš©ì ì§ˆë¬¸]: {question}")
        print("-" * 30) # ì‹œê°ì ì¸ êµ¬ë¶„ì„ 
        # --- ì‚¬ìš©ì ì§ˆë¬¸ ì¶œë ¥ ë ---

        # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì€ í›„ì— chain.invoke í˜¸ì¶œ
        try:
            response = chain.invoke(question) 
        except NameError:
            print("ì˜¤ë¥˜: 'chain' ê°ì²´ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LangChain ì…‹ì—… ì½”ë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            break
        except Exception as e:
            print(f"AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue
        
        # --- AI ë‹µë³€ í›„ì²˜ë¦¬ (Post-processing) ì‹œì‘ ---
        processed_response = response

        # 1. AIê°€ ìƒì„±í•œ ë¶ˆí•„ìš”í•œ <br> íƒœê·¸ ì œê±°
        processed_response = processed_response.replace("<br><br>", "")
        processed_response = processed_response.replace("<br>", "")

        # 2. ë¬¸ì¥ ë ë§ˆì¹¨í‘œ(.) ë’¤ì— ì¤„ ë°”ê¿ˆ ì¶”ê°€ (ë‘ ë‹¨ê³„ ì ‘ê·¼ ë°©ì‹)
        # 2-1ë‹¨ê³„: ë¬¸ì¥ ëìœ¼ë¡œ ë³´ì´ëŠ” '. ', '? ', '! ' ë’¤ì— ì¤„ë°”ê¿ˆ ë‘ ê°œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        # ì´ ê³¼ì •ì—ì„œ ì•½ì–´ ë’¤ì—ë„ ì„ì‹œì ìœ¼ë¡œ ì¤„ë°”ê¿ˆì´ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # '(?<=[.?!])'ëŠ” ë¬¸ì¥ ë¶€í˜¸ ë’¤ë¥¼ ì˜ë¯¸í•˜ê³ , '\s*'ëŠ” 0ê°œ ì´ìƒì˜ ê³µë°±, '([A-Zê°€-í£])'ëŠ” ëŒ€ë¬¸ì/í•œê¸€ ì‹œì‘ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
        processed_response = re.sub(r'(?<=[.?!])\s*([A-Zê°€-í£])', r'\n\n\1', processed_response)
        
        # 2-2ë‹¨ê³„: íŠ¹ì • ì•½ì–´ ë’¤ì— ë¶ˆí•„ìš”í•˜ê²Œ ìƒì„±ëœ ì¤„ë°”ê¿ˆ ì œê±° (ê³ ì • ê¸¸ì´ íŒ¨í„´ìœ¼ë¡œë§Œ ê°€ëŠ¥í•œ ì•½ì–´ë“¤)
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ì•½ì–´ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í•„ìš”ì— ë”°ë¼ ì¶”ê°€í•˜ê±°ë‚˜ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì£¼ì˜: ì´ë‹ˆì…œ(ì˜ˆ: J. K. Rowlingì˜ 'J.')ê³¼ ê°™ì´ ë‹¨ì¼ ëŒ€ë¬¸ìë¡œ ëœ ì•½ì–´ëŠ” ì™„ë²½í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ë¹„êµì  ê³ ì •ëœ í˜•íƒœì˜ ì•½ì–´ë“¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        common_abbreviations = [
            'Dr.', 'Mr.', 'Mrs.', 'Ms.', 'Sr.', 'Jr.', 'Prof.', 'Rev.', 'Capt.', 'Maj.', 'Col.', 'Gen.',
            'Hon.', 'e.g.', 'i.e.', 'etc.', 'vs.', 'U.S.', 'U.K.', 'Co.', 'Inc.', 'Ltd.', 'Fig.', 'Vol.', 'No.', 'Ave.', 'Blvd.', 'St.',
            # ì¶”ê°€ì ìœ¼ë¡œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì´ë‹ˆì…œ í˜•íƒœ ì˜ˆì™¸ (ëª©ë¡ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŒ)
            'A.', 'B.', 'C.', 'D.', 'E.', 'F.', 'G.', 'H.', 'I.', 'J.', 'K.', 'L.', 'M.', 'N.', 'O.', 'P.', 'Q.', 'R.', 'S.', 'T.', 'U.', 'V.', 'W.', 'X.', 'Y.', 'Z.'
        ]
        
        # ì•½ì–´ ë’¤ì˜ \n\nì„ ë‹¤ì‹œ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
        for abbr in common_abbreviations:
            # re.escapeë¥¼ ì‚¬ìš©í•˜ì—¬ ì•½ì–´ ë‚´ì˜ íŠ¹ìˆ˜ ë¬¸ì(ì˜ˆ: .)ë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            processed_response = re.sub(re.escape(abbr) + r'\n\n', abbr + ' ', processed_response)
            # í˜¹ì‹œ \në§Œ ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬ (ëœ ì¼ë°˜ì ì´ì§€ë§Œ, ì•ˆì „í•˜ê²Œ)
            processed_response = re.sub(re.escape(abbr) + r'\n', abbr + ' ', processed_response)

        # 3. ### ì œëª© ì•ë’¤ì— ë¹ˆ ì¤„ ì¶”ê°€ (Markdown í¬ë§· ìœ ì§€)
        processed_response = processed_response.replace("###", "\n\n###")
        if processed_response.startswith('\n\n###'):
            processed_response = processed_response[2:]
            
        # 'ë¶„ì„ ëŒ€ìƒ í•µì‹¬ ë…¼ë¬¸' ì œê±°ë¡œ ì¸í•´ ì´ êµ¬ë¶„ì„ ë„ ì œê±°
        processed_response = processed_response.replace("------------------------------------", "") 
        processed_response = processed_response.replace("------------------------------", "") 

        # 4. ëª©ë¡ ë²ˆí˜¸ì™€ ë‹¤ìŒ í…ìŠ¤íŠ¸ ì‚¬ì´ì— ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        processed_response = re.sub(r'(\d+\.)\s+', r'\1 ', processed_response)


        # --- AI ë‹µë³€ í›„ì²˜ë¦¬ ë ---

        print("\nğŸ“SOCY AssistantğŸ“:\n")
        print(processed_response) # ì²˜ë¦¬ëœ ë‹µë³€ì„ ì¶œë ¥
        print("-" * 30)

    # driver ê°ì²´ëŠ” ì´ ì½”ë“œ ë¸”ë¡ ì™¸ë¶€ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    try:
        if 'driver' in locals() and driver: # driverê°€ ë¡œì»¬ ìŠ¤ì½”í”„ì— ì •ì˜ë˜ì–´ ìˆê³  ìœ íš¨í•œì§€ í™•ì¸
            driver.close()
            print("Neo4j ë“œë¼ì´ë²„ ì—°ê²° ì¢…ë£Œ.")
    except NameError:
        print("ì˜¤ë¥˜: 'driver' ê°ì²´ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Neo4j ì—°ê²° ì½”ë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"Neo4j ë“œë¼ì´ë²„ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")