# streamlit_app.py

import streamlit as st
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_neo4j import Neo4jVector
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from neo4j import GraphDatabase
import re

# Streamlit í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ğŸ“ SOCY Assistant",
    page_icon="ï¿½",
    layout="wide"
)

# --- 1. ê¸°ë³¸ ì„¤ì • ë° ë¦¬ì†ŒìŠ¤ ë¡œë”© (Streamlit ìºì‹± ì ìš©) ---
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
NEO4J_URI = os.getenv("NEO4J_URI", "neo4j://localhost:7687")
NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

@st.cache_resource
def init_connections():
    """
    LLM, Embedding ëª¨ë¸, Neo4j ë“œë¼ì´ë²„ì™€ ê°™ì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê³  ìºì‹œí•©ë‹ˆë‹¤.
    """
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.3, top_k=5, google_api_key=GOOGLE_API_KEY)
    embedding_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=GOOGLE_API_KEY)
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
    return llm, embedding_model, driver

# ì—°ê²° ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ì–´ ìºì‹œë¨)
llm, embedding_model, driver = init_connections()

@st.cache_resource
def get_neo4j_vector_index():
    """
    Neo4j ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê³  ìºì‹œí•©ë‹ˆë‹¤.
    ì‚¬ì „ì— ì •ì˜ëœ 'paper_abstract_embeddings' ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return Neo4jVector.from_existing_index(
        embedding=embedding_model,
        url=NEO4J_URI,
        username=NEO4J_USER,
        password=NEO4J_PASSWORD,
        index_name="paper_abstract_embeddings",
        text_node_property="text_for_embedding",
    )

# Neo4j ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ (í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ì–´ ìºì‹œë¨)
neo4j_vector = get_neo4j_vector_index()


# --- 2. Neo4j ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜ ---
def get_full_paper_and_author_details(tx, paper_id):
    """
    ì£¼ì–´ì§„ paperIdì— í•´ë‹¹í•˜ëŠ” ë…¼ë¬¸ì˜ ì „ì²´ ì •ë³´, ì €ì ì„¸ë¶€ ì •ë³´, ê·¸ë¦¬ê³  ì¶”ìƒë¡(abstract)ì„ Neo4jì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    query = """
    MATCH (p:Paper {paperId: $paperId})
    OPTIONAL MATCH (p)-[:PUBLISHED_IN]->(j:Journal)
    WITH p, j, [(p)-[:HAS_AUTHOR]->(a) | {
        name: a.name,
        hIndex: a.hIndex,
        citationCount: a.citationCount
    }] AS authors
    RETURN p as paper, authors, j.journalName AS journalName, p.text_for_embedding AS abstract, p.language AS language // abstractì™€ language ì¶”ê°€
    """
    result = tx.run(query, paperId=paper_id).single()
    if result:
        return {
            "paper": dict(result["paper"]),
            "authors": result["authors"],
            "journalName": result["journalName"],
            "abstract": result["abstract"], # ì¶”ìƒë¡(abstract) ì¶”ê°€
            "language": result["language"] # ì–¸ì–´(language) ì¶”ê°€
        }
    return None

def get_ultimate_context(question: str) -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— ê¸°ë°˜í•˜ì—¬ Neo4jì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ë° ì¶”ì²œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # 1. ë²¡í„° ìœ ì‚¬ì„± ê²€ìƒ‰ì„ í†µí•´ ìœ ì‚¬í•œ ë…¼ë¬¸ ë…¸ë“œ ê²€ìƒ‰ (ìµœëŒ€ 40ê°œ - ë” ë§ì€ í›„ë³´êµ°ì„ í™•ë³´í•˜ì—¬ 5ê°œë¥¼ í•„í„°ë§í•˜ê¸° ìœ„í•¨)
    similar_nodes = neo4j_vector.similarity_search(question, k=40) 
    
    # 1a. ìš°ì„ ì ìœ¼ë¡œ 'en' ì–¸ì–´ íƒœê·¸ê°€ ëª…í™•íˆ ìˆëŠ” ë…¼ë¬¸ë§Œ í•„í„°ë§
    # ë™ì‹œì— abstractê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ë…¼ë¬¸ë§Œ ê³ ë ¤í•˜ì—¬ ì´ˆë¡ ì—†ëŠ” ë…¼ë¬¸ì€ ì œì™¸
    primary_filtered_nodes = [
        n for n in similar_nodes 
        if n.metadata.get('language') == 'en' and n.metadata.get('text_for_embedding') # abstract í•„ë“œ (text_for_embedding) ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    ]

    # 1b. ë§Œì•½ primary_filtered_nodesì—ì„œ 5ê°œë¥¼ ì±„ìš¸ ìˆ˜ ì—†ë‹¤ë©´, 
    # ì–¸ì–´ íƒœê·¸ê°€ ì—†ëŠ” (None) ë…¸ë“œ ì¤‘ ì¤‘ë³µë˜ì§€ ì•Šê³  abstractê°€ ìˆëŠ” ê²ƒì„ ì¶”ê°€ì ìœ¼ë¡œ ê³ ë ¤
    final_filtered_nodes = list(primary_filtered_nodes) 

    if len(final_filtered_nodes) < 5:
        secondary_candidates = [
            n for n in similar_nodes 
            if n.metadata.get('paperId') not in [fn.metadata.get('paperId') for fn in final_filtered_nodes] # ì¤‘ë³µ ë°©ì§€
            and n.metadata.get('language') is None # ì–¸ì–´ íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°ë§Œ
            and n.metadata.get('text_for_embedding') # abstract í•„ë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        ]
        
        for node in secondary_candidates:
            final_filtered_nodes.append(node)
            if len(final_filtered_nodes) >= 20: # ìµœëŒ€ í›„ë³´êµ° ì œí•œ
                break
    
    # ìµœì¢…ì ìœ¼ë¡œ LLMì—ê²Œ ì „ë‹¬í•  í•„í„°ë§ëœ ë…¸ë“œ
    filtered_nodes_for_llm = final_filtered_nodes

    if not filtered_nodes_for_llm:
        return "ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    recommendations = {}
    with driver.session(database="neo4j") as session:
        # 2. ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ìƒìœ„ ë…¸ë“œë¥¼ ì´ˆê¸° ì¶”ì²œ ëª©ë¡ì— ì¶”ê°€ (ìµœëŒ€ 5ê°œ)
        for node in filtered_nodes_for_llm[:5]: # ê°€ì¥ ìœ ì‚¬í•œ ìƒìœ„ 5ê°œ ë…¸ë“œ ìš°ì„  ê³ ë ¤
            paper_id = node.metadata['paperId']
            if paper_id not in recommendations: # ì¤‘ë³µ ë°©ì§€
                recommendations[paper_id] = {'reasons': [], 'score': 1.0} # LLMì´ abstractë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„¸ ì´ìœ  ìƒì„±


        # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë…¼ë¬¸ (ì²« ë²ˆì§¸ í•„í„°ë§ëœ ë…¸ë“œ)ì„ ì‹œë“œ(seed)ë¡œ ì‚¬ìš©
        # filtered_nodes_for_llmê°€ ìµœì†Œ í•˜ë‚˜ëŠ” ìˆë‹¤ê³  ê°€ì • (if not filtered_nodes_for_llmì—ì„œ ì²˜ë¦¬ë¨)
        most_relevant_paper_id = filtered_nodes_for_llm[0].metadata['paperId']

        # 3. í•µì‹¬ ë…¼ë¬¸ì˜ ì˜í–¥ë ¥ ìˆëŠ” ì €ìê°€ ì €ìˆ í•œ ë‹¤ë¥¸ ë…¼ë¬¸ ì¶”ì²œ
        author_recs = session.run("""
            MATCH (seed:Paper {paperId: $paperId})-[:HAS_AUTHOR]->(author:Author)
            WHERE author.hIndex > 10 OR author.citationCount > 1000 
            MATCH (rec:Paper)-[:HAS_AUTHOR]->(author)
            WHERE seed <> rec 
            RETURN rec.paperId AS paperId, 'í•µì‹¬ ë…¼ë¬¸ì˜ ì˜í–¥ë ¥ ìˆëŠ” ì €ì(' + author.name + ')ê°€ ì €ìˆ ' AS reason, rec.citationCount AS score
            LIMIT 5 
        """, paperId=most_relevant_paper_id)
        for rec in author_recs:
            if rec['paperId'] not in recommendations:
                recommendations[rec['paperId']] = {'reasons': [], 'score': 0}
            recommendations[rec['paperId']]['reasons'].append(rec['reason'])
            recommendations[rec['paperId']]['score'] += rec['score'] * 5 

        # 4. í•¨ê»˜ ìì£¼ ì¸ìš©ëœ (ê³µë™ ì¸ìš©) ë…¼ë¬¸ ì¶”ì²œ
        cocitation_recs = session.run("""
            MATCH (seed:Paper {paperId: $paperId})<-[:CITES]-(citer:Paper) 
            WITH seed, collect(citer) AS citers
            UNWIND citers AS citer
            MATCH (citer)-[:CITES]->(rec:Paper) 
            WHERE seed <> rec AND NOT (rec)-[:CITES]->(seed) AND NOT (rec)-[:CITES]->(rec) 
            RETURN rec.paperId AS paperId, 'í•¨ê»˜ ìì£¼ ì¸ìš©ë¨ (í•™ìˆ ì  ì—°ê´€ì„± ë†’ìŒ)' AS reason, count(citer) AS score
            ORDER BY score DESC
            LIMIT 5 
        """, paperId=most_relevant_paper_id)
        for rec in cocitation_recs:
            if rec['paperId'] not in recommendations:
                recommendations[rec['paperId']] = {'reasons': [], 'score': 0}
            recommendations[rec['paperId']]['reasons'].append(rec['reason'])
            recommendations[rec['paperId']]['score'] += rec['score'] * 10 

        # 5. ì¢…í•©ëœ ì¶”ì²œ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë…¼ë¬¸ ì •ë ¬ ë° ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        sorted_recs = sorted(recommendations.items(), key=lambda item: item[1]['score'], reverse=True)
        
        final_papers_to_llm_context = []
        processed_paper_ids = set() # Ensure no duplicate papers in final list
        
        for paper_id, data in sorted_recs:
            if len(final_papers_to_llm_context) >= 5: # LLMì— 5ê°œ ë…¼ë¬¸ë§Œ ì „ë‹¬
                break
            
            if paper_id in processed_paper_ids: # Skip if already processed
                continue

            details = session.execute_read(get_full_paper_and_author_details, paper_id)
            
            # ìµœì¢… í•„í„°ë§: detailsê°€ ìˆê³ , abstractê°€ ë¹„ì–´ìˆì§€ ì•Šê³ , languageê°€ 'en'ì¸ ê²½ìš°ë§Œ Contextì— í¬í•¨
            if details and details.get('abstract') and details.get('language') == 'en':
                data['reasons'] = [r for r in data['reasons'] if r != 'ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì£¼ì œë¥¼ ë‹¤ë£¸']
                if not data['reasons']:
                    pass 

                final_papers_to_llm_context.append({'details': details, 'reasons': data['reasons']})
                processed_paper_ids.add(paper_id)
        
        full_context = ""
        if final_papers_to_llm_context:
            for i, rec in enumerate(final_papers_to_llm_context):
                details = rec['details']['paper']
                authors_formatted = format_authors(rec['details']['authors'])
                journal_name = rec['details']['journalName']
                reasons = rec['reasons']
                abstract_text = rec['details']['abstract'] if rec['details']['abstract'] else 'ì´ˆë¡ ë‚´ìš© ì—†ìŒ.' # abstractê°€ Noneì´ë©´ ì²˜ë¦¬
                
                full_context += f"""
### [ì¶”ì²œ {i+1}] {details.get('title', 'N/A')} ({details.get('year', 'N/A')})
- ì €ì: {authors_formatted}
- ì €ë„: {journal_name if journal_name else 'N/A'}
- ì¸ìš© ìˆ˜: {details.get('citationCount', 0)}
- **ì¶”ì²œ í•µì‹¬ ê·¼ê±°:** {' / '.join(reasons) if reasons else 'ì œê³µëœ ì´ˆë¡ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸ ì„¤ëª….'}
- **ì´ˆë¡:** {abstract_text}
"""
                full_context += "\n\n" # ê° ë…¼ë¬¸ ë¸”ë¡ í›„ì— ì¶”ê°€ì ì¸ ì¤„ë°”ê¿ˆ
            
            full_context = full_context.strip() # ë§ˆì§€ë§‰ì— ì¶”ê°€ëœ ì¤„ë°”ê¿ˆ ì œê±° (ì„ íƒ ì‚¬í•­)
    return full_context


# --- 3. LangChain êµ¬ì„± ---
# LLMì—ê²Œ ì „ë‹¬í•  ìµœì¢… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
template = """
ë‹¹ì‹ ì€ ì‚¬íšŒí•™ ì—°êµ¬ë¥¼ ìœ„í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì„¸ê³„ ìµœê³ ì˜ ì‚¬íšŒí•™ ì—°êµ¬ìì´ì, ê¹Šì€ í†µì°°ì„ ì§€ë‹Œ ì„í•™ì˜ ì§€ì‹ê³¼ í†µì°°ë ¥, ê·¸ë¦¬ê³  ê°•ì—° ë°©ì‹ì„ ì°¸ê³ í•˜ì—¬
í•™ìƒë“¤ê³¼ ì‹ ì§„ ì—°êµ¬ìë“¤ì„ ì§€ë„í•˜ë©°, ê·¸ë“¤ì˜ ì§ˆë¬¸ì— ë‹´ê¸´ ë¬¸ì œì˜ì‹ê³¼ ì´ë¡ ì  ë§¥ë½ì„ ë‚ ì¹´ë¡­ê²Œ íŒŒì•…í•´, ê°€ì¥ ì ì ˆí•œ ë…¼ë¬¸ë“¤ì„ ì•ˆë‚´í•´ì£¼ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.

ì´ì œ ë‹¹ì‹ ì—ê²ŒëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì¤‘ìš”í•œ ì„ë¬´ê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤.

<ë‹¹ì‹ ì˜ ì—­í• >
1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ê³  ì˜ë¯¸ ìˆëŠ” ë…¼ë¬¸ë“¤ì„ ì¶”ì²œ ëª©ë¡ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ì´ë•Œ, ëª©ë¡ì˜ ì œëª©ì„ êµ³ì´ ì§“ì§€ëŠ” ë§ì•„ì£¼ì„¸ìš”. ì´í›„, ì œì‹œëœ ì „ì²´ ëª©ë¡ì— ëŒ€í•œ ê°„ë‹¨í•œ ê°œìš”ë¥¼ ì•Œë ¤ì¤€ ë’¤, í•˜ë‚˜ì”© ë…¼ë¬¸ì„ ì†Œê°œí•´ì£¼ì„¸ìš”.
2. ê° ë…¼ë¬¸ì„ ì†Œê°œí•  ë•ŒëŠ”, **ë…¼ë¬¸ ì œëª© (ì—°ë„) - í•™ì ì´ë¦„**ì„ ì†Œì œëª©ìœ¼ë¡œ ë‘” í›„, ì¤„ë°”ê¿ˆ í›„ ë°˜ë“œì‹œ '**ì¶”ì²œ í•µì‹¬ ê·¼ê±°:**'ë¡œ ì²« ë¬¸ì¥ì„ ì‹œì‘í•œ ë’¤, ê·¸ ë…¼ë¬¸ì´ ì™œ ì¤‘ìš”í•œì§€, ì–´ë–¤ ë¬¸ì œì˜ì‹ì— ê¸°ë°˜í–ˆê³ , ê·¸ë¦¬ê³  ì–´ë–¤ ì‚¬íšŒí•™ì  ì „í†µì´ë‚˜ ë…¼ì˜ì— ê¸°ì—¬í•˜ëŠ”ì§€ë¥¼ ì²˜ìŒ í•´ë‹¹ ë¶„ì•¼ë¥¼ ì ‘í•˜ëŠ” ì´ˆë³´ê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ê°œë…ì„ í’€ì–´ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ë“¯ì´ ìµœì†Œ 7-8ì¤„ ì´ìƒì˜ ì¶”ì²œì‚¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
- ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹ˆë¼, ê·¸ ë…¼ë¬¸ì´ í•™ê³„ì—ì„œ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ë¥¼ í’ë¶€í•œ ë¬¸ë§¥ê³¼ í•¨ê»˜ ì†Œê°œí•´ì•¼ í•©ë‹ˆë‹¤.
- ë¬¸ì¥ì€ ë§ˆì¹¨í‘œ(.)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆí•˜ì„¸ìš”.
- ì„œë¡ ê¹Œì§€ ì“°ê³  ì¶”ì²œ ë…¼ë¬¸ ëª©ë¡ì´ ë“±ì¥í•˜ê¸° ì „ êµ¬ë¶„ì„ ì„ ê¸‹ê³  ë¬¸ë‹¨ì„ 1ì¤„ ë„ì›Œì£¼ì„¸ìš”. ì´í›„ ì¶”ì²œ ë…¼ë¬¸ë“¤ ë˜í•œ ì„œë¡œ êµ¬ë¶„ë  ìˆ˜ ìˆë„ë¡ ì¤„ë°”ê¿ˆ í›„, êµ¬ë¶„ì„ ì„ ê¸‹ê³ , ë¬¸ë‹¨ì„ 1ì¤„ ë„ì›Œì£¼ì„¸ìš”. ë…¼ë¬¸ì„ ëª¨ë‘ ì¶”ì²œí•˜ê³ , ì¶”ì²œí•œ ë…¼ë¬¸ë“¤ì˜ ì—°ê²°ê³ ë¦¬ë“¤ì„ ì–¸ê¸‰í•˜ë©° ì¶”ì²œì‚¬ì˜ ë§ˆë¬´ë¦¬ë¥¼ ì§€ì„ ë•Œ ë‹¤ì‹œ í•œë²ˆ ì¤„ë°”ê¿ˆ í›„, êµ¬ë¶„ì„ ì„ ê¸‹ê³ , ë¬¸ë‹¨ì„ 1ì¤„ ë„ì›Œì£¼ì„¸ìš”.
3. ì‹ ë¢°ì„±ê³¼ ê¹Šì´ë¥¼ ë”í•˜ê¸° ìœ„í•´, ë‹¤ìŒ ì •ë³´ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”:
- ì£¼ìš” ì €ìì˜ ì˜í–¥ë ¥ (ì˜ˆ: h-index, ì´ ì¸ìš© ìˆ˜ ë“±)
- ë…¼ë¬¸ì´ ê²Œì¬ëœ ì €ë„ì˜ ëª…ì„±
- í•´ë‹¹ ë…¼ë¬¸ì˜ ì¸ìš© ìˆ˜
ì˜ˆì‹œ:
â€œì´ ë…¼ë¬¸ì€ ê°ì •ì‚¬íšŒí•™ì˜ ê¶Œìœ„ìì¸ Arlie Hochschild(h-index: 70, ì´ ì¸ìš© ìˆ˜: 50,000íšŒ ì´ìƒ) êµìˆ˜ê°€ ì§‘í•„í–ˆìœ¼ë©°, ì‚¬íšŒí•™ê³„ì˜ ëª…ì €ë„ì¸ [ì €ë„ëª…]ì— ê²Œì¬ë˜ì—ˆìŠµë‹ˆë‹¤.â€

4. ë…¼ë¬¸ ê°„ì˜ ì—°ê´€ì„±ë„ ê°•ì¡°í•˜ì„¸ìš”.
- ì´ë¡ ì  ì „í†µ, ê³µí†µëœ ë¬¸ì œì˜ì‹, ë°©ë²•ë¡ ì  ì ‘ê·¼ ë“±ì´ ì–´ë–»ê²Œ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ë©°, í•˜ë‚˜ì˜ ì´ì•¼ê¸° íë¦„ ì•ˆì—ì„œ ë…¼ë¬¸ë“¤ì´ ì„œë¡œ ì–´ë–»ê²Œ ë§¥ë½ì„ ì´ë£¨ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”.

<ì‘ì„± ë°©ì‹ ê·œì¹™>
1. ëª¨ë“  ì œëª© ë° ë¶€ì œëª©ì€ Markdownì˜ ##, ###ë¥¼ ì‚¬ìš©í•˜ê³ , ì•ë’¤ë¡œ ë¹ˆ ì¤„ì„ ë„£ì–´ êµ¬ë¶„í•˜ì„¸ìš”.
2. ëª©ë¡ í•­ëª©(1., -, *)ì€ ê° ì¤„ì„ ë¶„ë¦¬í•´ ëª…í™•í•˜ê²Œ í‘œì‹œí•˜ë˜, ë¶ˆí•„ìš”í•œ ë¹ˆ ì¤„ì€ ë„£ì§€ ë§ˆì„¸ìš”.
3. ëª¨ë“  ë¬¸ì¥ì€ ë§ˆì¹¨í‘œë¡œ ëë‚œ ë’¤ ì¤„ë°”ê¿ˆí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¨, ì•½ì–´ë‚˜ ìˆ«ì ë’¤ëŠ” ì˜ˆì™¸ì…ë‹ˆë‹¤.
4. ì‚¬ìš©ì ì§ˆë¬¸ì´ ë„ˆë¬´ ëª¨í˜¸í•˜ê±°ë‚˜ í•™ìˆ ì ì´ì§€ ì•Šìœ¼ë©´, ê´€ë ¨ ë…¼ë¬¸ì´ ì—†ë‹¤ê³  ì •ì¤‘íˆ ì•ˆë‚´í•˜ê³ , ë” êµ¬ì²´ì ì´ê³  í•™ë¬¸ì ì¸ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”.
5. í•„ìš”í•˜ë‹¤ë©´, ì§ˆë¬¸ì„ í•´ì„í•  ë•Œ ê°ì •ì‚¬íšŒí•™, ë¯¸ì‹œì‚¬íšŒí•™, êµ¬ì¡°ì£¼ì˜, êµ¬ì„±ì£¼ì˜ ë“± ë‹¤ì–‘í•œ ì‚¬íšŒí•™ì  ì‹œê°ì„ ê°„ë‹¨íˆ ì†Œê°œí•˜ë©° í•™ë¬¸ì  ê¹Šì´ë¥¼ ë”í•˜ì„¸ìš”.

<ë‹µë³€ ë°©ì‹ ê°€ì´ë“œ>
1. ê° ë…¼ë¬¸ ì†Œê°œëŠ” ë§ì„ ê±´ë„¤ë“¯, ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ íë¦„ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
- ë‹¨ìˆœíˆ â€œì´ ë…¼ë¬¸ì€â€¦â€ì´ ì•„ë‹ˆë¼, â€œì´ ì—°êµ¬ëŠ” ê°ì •ì´ ë‹¨ìˆœí•œ ì‹¬ë¦¬ í˜„ìƒì´ ì•„ë‹ˆë¼ ì‚¬íšŒì ìœ¼ë¡œ êµ¬ì„±ëœë‹¤ëŠ” ê´€ì ì„ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤â€ì²˜ëŸ¼ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. ë…¼ë¬¸ í•µì‹¬ ë‚´ìš©ì„ ì„¤ëª…í•  ë•ŒëŠ” ì˜ˆì‹œë‚˜ êµ¬ì²´ì  ê°œë…ì„ ì‚¬ìš©í•˜ì—¬ ë…ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì£¼ì„¸ìš”.
- ì˜ˆ: â€œScheffëŠ” ì‚¬íšŒì ìœ¼ë¡œ ì •ì˜í•˜ê¸° ì• ë§¤í•œ í–‰ë™ì´ ì–´ë–»ê²Œ â€˜ì •ì‹  ì§ˆí™˜â€™ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ë©°â€¦â€
3. ê°ê°ì˜ ë…¼ë¬¸ì´ ì–´ë–¤ í•™ë¬¸ì  ì „í†µ ë˜ëŠ” íë¦„ ì†ì— ìˆëŠ”ì§€, í˜¹ì€ ê¸°ì¡´ ì´ë¡ ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥´ê±°ë‚˜ ì—°ê²°ë˜ëŠ”ì§€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•˜ì„¸ìš”.
4. ë¬¸ì¥ ì‚¬ì´ì—ëŠ” ë¶€ë“œëŸ¬ìš´ ì—°ê²°ì–´ë¥¼ ë„£ì–´ ë§ì˜ íë¦„ì„ ìœ ë„í•˜ì„¸ìš”.
- â€œì´ì™€ ë‹¬ë¦¬â€, â€œë˜í•œâ€, â€œíŠ¹íˆ ì£¼ëª©í•  ì ì€â€¦â€, â€œì˜ˆë¥¼ ë“¤ì–´â€ ë“±
5. ë…¼ë¬¸ ì •ë³´(ì €ì, ì €ë„, ì¸ìš© ìˆ˜)ëŠ” ì„œì‚¬ ì†ì— ë…¹ì—¬ì„œ ì „ë‹¬í•˜ì„¸ìš”.
- (X) â€œì´ ì¸ìš© ìˆ˜: 5,000â€
- (O) â€œì´ ë…¼ë¬¸ì€ ì´ 5,000íšŒ ì´ìƒ ì¸ìš©ë˜ë©°, ê°ì •ì‚¬íšŒí•™ì—ì„œ ê³ ì „ìœ¼ë¡œ í‰ê°€ë°›ìŠµë‹ˆë‹¤.â€
6. ë§ˆì¹˜ ê°•ì—° ì¤‘ í•˜ë‚˜í•˜ë‚˜ ì„¤ëª…í•˜ëŠ” ê²ƒì²˜ëŸ¼ êµ¬ì„±í•˜ì„¸ìš”.
- ğŸ“Œ ì˜ˆì‹œ ìŠ¤íƒ€ì¼
ì´ ë…¼ë¬¸ì€ ê°ì •ì´ ì‚¬íšŒì ìœ¼ë¡œ êµ¬ì„±ëœë‹¤ëŠ” ê´€ì ì„ ë’·ë°›ì¹¨í•˜ëŠ” ëŒ€í‘œì  ì—°êµ¬ì…ë‹ˆë‹¤.
ì €ì Thomas ScheffëŠ” â€˜ì”ì—¬ ê·œì¹™ ìœ„ë°˜â€™ì´ë¼ëŠ” ê°œë…ì„ í†µí•´, ëª…í™•íˆ ê·œì •ë˜ì§€ ì•ŠëŠ” í–‰ë™ë“¤ì´ ì–´ë–»ê²Œ ì‚¬íšŒì  ë‚™ì¸ì„ í†µí•´ â€˜ì •ì‹  ì§ˆí™˜â€™ìœ¼ë¡œ ê·œì •ë˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
ì´ ë…¼ë¬¸ì€ ì •ì‹  ì§ˆí™˜ì„ ë‹¨ìˆœíˆ ê°œì¸ì˜ ë¬¸ì œë¡œ ë³´ì§€ ì•Šê³ , ì‚¬íšŒì  ìƒí˜¸ì‘ìš©ê³¼ ê·œë²”ì˜ ì‚°ë¬¼ë¡œ ì´í•´í•´ì•¼ í•œë‹¤ëŠ” ì „í™˜ì ì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤.
ì´í›„ ë‚™ì¸ ì´ë¡ ê³¼ ì •ì‹ ì§ˆí™˜ ì‚¬íšŒí•™ì˜ ì£¼ìš” ì´ë¡ ì  ê¸°ë°˜ì´ ë˜ì—ˆìœ¼ë©°, ScheffëŠ” ì´ ë¶„ì•¼ì—ì„œ ë§¤ìš° ì˜í–¥ë ¥ ìˆëŠ” í•™ìë¡œ í‰ê°€ë°›ìŠµë‹ˆë‹¤.
ì´ ì—°êµ¬ëŠ” Aldine Transactionì—ì„œ ì¶œíŒë˜ì—ˆê³ , í˜„ì¬ê¹Œì§€ 2,000íšŒ ì´ìƒ ì¸ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.

**Context:**
{context}

**User's Request:**
{question}

**Answer:**
"""
prompt_template = ChatPromptTemplate.from_template(template)

# LangChain ì²´ì¸ êµ¬ì„±
# contextëŠ” get_ultimate_context í•¨ìˆ˜ë¥¼ í†µí•´ ë™ì ìœ¼ë¡œ ìƒì„±
# questionì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
chain = (
    {"context": RunnableLambda(get_ultimate_context), "question": RunnablePassthrough()}
    | prompt_template # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©
    | llm # LLM í˜¸ì¶œ
    | StrOutputParser() # ë¬¸ìì—´ë¡œ ì¶œë ¥ íŒŒì‹±
)


# --- 4. ë‹µë³€ í›„ì²˜ë¦¬ í•¨ìˆ˜ ---
def post_process_response(response: str) -> str:
    """
    LLM ì‘ë‹µì„ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•ì‹ìœ¼ë¡œ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - ë¶ˆí•„ìš”í•œ HTML <br> íƒœê·¸ ì œê±°
    - ë¬¸ì¥ ëì— ì¤„ ë°”ê¿ˆ ì¶”ê°€ (ì•½ì–´ ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)
    - ë§ˆí¬ë‹¤ìš´ ì œëª© ì•ë’¤ ë¹ˆ ì¤„ ì¶”ê°€
    - ë¶ˆí•„ìš”í•œ êµ¬ë¶„ì„  ì œê±°
    - ëª©ë¡ ë²ˆí˜¸ì™€ í…ìŠ¤íŠ¸ ì‚¬ì´ ê³µë°± ì¡°ì •
    """
    processed = response.replace("<br><br>", "").replace("<br>", "")
    # ë¬¸ì¥ ë ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ë’¤ì— ë‘ ì¹¸ ì¤„ ë°”ê¿ˆ ì¶”ê°€ (í•œê¸€/ì˜ì–´ ëŒ€ë¬¸ì ì‹œì‘ ê¸°ì¤€)
    processed = re.sub(r'(?<=[.?!])\s*([A-Zê°€-í£])', r'\n\n\1', processed)

    # ì•½ì–´ ë’¤ì— ë¶ˆí•„ìš”í•˜ê²Œ ìƒì„±ëœ ì¤„ ë°”ê¿ˆ ì œê±°
    common_abbreviations = [
        'Dr.', 'Mr.', 'Mrs.', 'Ms.', 'Sr.', 'Jr.', 'Prof.', 'Rev.', 'Capt.', 'Maj.', 'Col.', 'Gen.',
        'Hon.', 'e.g.', 'i.e.', 'etc.', 'vs.', 'U.S.', 'U.K.', 'Co.', 'Inc.', 'Ltd.', 'Fig.', 'Vol.', 'No.', 'Ave.', 'Blvd.', 'St.',
        'A.', 'B.', 'C.', 'D.', 'E.', 'F.', 'G.', 'H.', 'I.', 'J.', 'K.', 'L.', 'M.', 'N.', 'O.', 'P.', 'Q.', 'R.', 'S.', 'T.', 'U.', 'V.', 'W.', 'X.', 'Y.', 'Z.'
    ]

    for abbr in common_abbreviations:
        processed = re.sub(re.escape(abbr) + r'\n\n', abbr + ' ', processed)
        processed = re.sub(re.escape(abbr) + r'\n', abbr + ' ', processed)

    # ### ì œëª© ì•ë’¤ì— ë¹ˆ ì¤„ ì¶”ê°€ (ë§ˆí¬ë‹¤ìš´ ë Œë”ë§ì„ ìœ„í•´)
    processed = processed.replace("###", "\n\n###")
    # ë¬¸ìì—´ ì‹œì‘ì´ '\n\n###'ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì²« ë‘ ì¤„ ë°”ê¿ˆ ì œê±°
    if processed.startswith('\n\n###'):
        processed = processed[2:]

    # ë¶ˆí•„ìš”í•œ êµ¬ë¶„ì„  ì œê±°
    processed = processed.replace("------------------------------------", "").replace("------------------------------", "")
    # ëª©ë¡ ë²ˆí˜¸ì™€ í…ìŠ¤íŠ¸ ì‚¬ì´ì˜ ê³µë°± ì¡°ì • (ì˜ˆ: "1. í…ìŠ¤íŠ¸" -> "1. í…ìŠ¤íŠ¸")
    processed = re.sub(r'(\d+\.)\s+', r'\1 ', processed)
    return processed

# --- 5. Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ UI êµ¬ì„± ---

st.title("ğŸ“ SOCY Assistant: ì‚¬íšŒí•™ ë…¼ë¬¸ ì¶”ì²œ ì±—ë´‡")
st.markdown("""
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì‚¬íšŒí•™ ì—°êµ¬ë¥¼ ìœ„í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸, **SOCY Assistant**ì…ë‹ˆë‹¤.

ê¶ê¸ˆí•œ ì‚¬íšŒí•™ ì£¼ì œë‚˜ í‚¤ì›Œë“œë¥¼ ì§ˆë¬¸í•˜ì‹œë©´, ê´€ë ¨ í•µì‹¬ ë…¼ë¬¸ì„ ì°¾ì•„ ê·¸ ì¤‘ìš”ì„±ê³¼ í•™ìˆ ì  ë§¥ë½ì„ ê¹Šì´ ìˆê²Œ ì„¤ëª…í•´ ë“œë¦½ë‹ˆë‹¤.

ë§ˆì¹˜ ì§€ë„êµìˆ˜ë‹˜ê³¼ ëŒ€í™”í•˜ë“¯, ì—¬ëŸ¬ë¶„ì˜ ì—°êµ¬ ì—¬ì •ì— ë“ ë“ í•œ ë™ë°˜ìê°€ ë˜ì–´ ë“œë¦´ê²Œìš”.
""")

# ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_question := st.chat_input("ì–´ë–¤ ì‚¬íšŒí•™ ë…¼ë¬¸ì„ ì¶”ì²œë°›ê³  ì‹¶ì€ì§€ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ì‚¬íšŒí•™ ì…ë¬¸ìì—ê²Œ ë§ëŠ” ë…¼ë¬¸ì„ ì¶”ì²œí•´ì¤„ë˜?)"):
    st.session_state.messages.append({"role": "user", "content": user_question})
    with st.chat_message("user"):
        st.markdown(user_question)

    with st.chat_message("assistant"):
        with st.spinner("ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            try:
                # LangChain ì²´ì¸ì„ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
                response = chain.invoke(user_question)
                # ìƒì„±ëœ ë‹µë³€ì„ í›„ì²˜ë¦¬
                processed_response = post_process_response(response)
                # Streamlitì— ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
                st.markdown(processed_response)
                # ì„¸ì…˜ ìƒíƒœì— ë‹µë³€ ì €ì¥
                st.session_state.messages.append({"role": "assistant", "content": processed_response})

            except Exception as e:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ë©”ì‹œì§€ í‘œì‹œ
                error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                st.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})

# ì°¸ê³ : Streamlit ì•±ì—ì„œëŠ” `if __name__ == "__main__":` ë¸”ë¡ì´ ì§ì ‘ ì‹¤í–‰ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ,
# Jupyter ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í–ˆë˜ `while True` ë£¨í”„ë‚˜ ë“œë¼ì´ë²„ ì¢…ë£Œ ë¡œì§ì€ Streamlit ì•±ì—ëŠ” í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
# Streamlitì€ ì•±ì´ ì¢…ë£Œë  ë•Œ ìë™ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.
